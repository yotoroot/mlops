---
layout: default
title: Torchserve
nav_order: 3
has_children: true
permalink: /docs/torchserve
---

# Kubeflow for Torchserve

TorchServe and KServe can be integrated to enable the deployment and management of PyTorch models using the KServe framework. This integration allows for seamless integration of PyTorch models into existing KServe deployments, leveraging KServe's capabilities for model serving, scaling, and monitoring.

Key Benefits of Integrating TorchServe with KServe:

Unified Model Management: Combine the strengths of TorchServe's model serving capabilities with KServe's broader model management functionalities.

Simplified Model Deployment: Leverage KServe's infrastructure and orchestration tools to streamline the deployment and scaling of PyTorch models.

Enhanced Model Monitoring: Utilize KServe's built-in monitoring capabilities to track model performance, resource utilization, and potential issues.

Flexible Model Serving Options: Choose between KServe's REST API or gRPC protocol for serving PyTorch models.

{: .fs-6 .fw-300 }